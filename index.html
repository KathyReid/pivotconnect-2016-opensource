<!doctype html>

<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1024" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <title>Open source – how sharing software and hardware makes technology
better for all of us | Kathy Reid | Pivot Connect 2016 </title>

    <meta name="description" content="Presentation for Pivot Connect, Geelong, November 2016" />
    <meta name="author" content="Kathy Reid <kathy@kathyreid.id.au>" />

    <link href="css/impress-pivotconnect-2016.css" rel="stylesheet" />

    <link rel="shortcut icon" href="favicon.png" />
    <link rel="apple-touch-icon" href="apple-touch-icon.png" />
</head>
<body class="impress-not-supported">

<!--
    For example this fallback message is only visible when there is `impress-not-supported` class on body.
-->
<div class="fallback-message">
    <p>Your browser <b>doesn't support the features required</b> by impress.js, so you are presented with a simplified version of this presentation.</p>
    <p>For the best experience please use the latest <b>Chrome</b>, <b>Safari</b> or <b>Firefox</b> browser.</p>
</div>

<header>
  <ul>
    <li>@KathyReid</li>
    <li>Open source – sharing technology</li>
    <li><img src="img/pivotconnect-logo.png" width="160px"></li>
  </ul>
</header>

<div id="Licence">
  <img src="img/CC-BY-SA_icon.svg" width="100" alt="Licence - CC BY SA">
</div>

<div id="impress">

    <!-- INTRODUCTORY SLIDES -->

    <div id="Introduction" class="step" data-x="-1500" data-y="0">
      <h1>Open source software and hardware</h1>
      <p>&nbsp;</p>
      <h3>Why sharing technology makes the future better for us all</h3>
    </div>

    <div id="GitHub" class="step" data-x="-1000" data-y="0">
    <img src="img/github.png" width="200" alt="GitHub">
    <h3><strong>@KathyReid</strong> on GitHub, Twitter, IRC, Slack etc</h3>
    <h3><a href="http://www.kathyreid.com.au">kathyreid.com.au</a></h3>
    <h3>Treasurer, Creative Geelong and Vice-President, Linux Australia</h3>
    </div>

    <div id="WhatIsOpensource" class="step slide" data-x="1500" data-y="0">
    <h2>What are open source technologies?</h2>
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/b6WaSP">More questions than answers</em> via Tom Waterhouse on Flickr.</a></p>
    </div>

    <div id="LookInside" class="step slide" data-x="2000" data-y="0">
    <h2 class="white top50">Open up, look inside, see how it works</h2>
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/hJHW1C">Looking up</em> via Son of Groucho on Flickr.</a></p>
    </div>

    <div id="WordPress" class="step slide" data-x="2500" data-y="0">
    <h2>1 in 4 websites in the world</h2>
    </div>






    <div id="PunchCard" class="step slide" data-x="-4500" data-y="-2000">
    <h2>Punch cards? FML.</h2>
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/6zRRK2">Punch Cards</em> via Chris Limb on Flickr.</a></p>
    </div>

    <div id="OldKeyboards" class="step slide" data-x="-3001" data-y="-2000">
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/ewu3v8">Terminal Znakowy MERA 7951 OM Mera-ELZAB MERAMAT</em> via Arkadiusz Sikorski on Flickr.</a></p>
    </div>

    <div id="OldMouse" class="step slide" data-x="-1501" data-y="-2000">
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/6z3xSg">Macintosh Mouse</em> via Marcin Wichary on Flickr.</a></p>
    </div>

    <div id="GraphicsTablet" class="step slide" data-x="1" data-y="-2000">
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/4v358f">BAMBOOFun16</em> via Shou-Hui Wang on Flickr.</a></p>
    </div>

    <div id="WiiMote" class="step slide" data-x="1501" data-y="-2000">
    </div>

    <div id="TransformerTrio" class="step slide" data-x="3002" data-y="-2000">
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/myPbWs">Asus TX201LA Transformer Book Series Laptop</em> via India7 Network on Flickr.</a></p>
    </div>

    <!--- TRENDS AND DRIVERS -->

    <div id="TrendsDrivers" class="step" data-x="-6000" data-y="-1000">
    <h1>Drivers for change in user interfaces</h1>
    <h3>Paradigm shifts, instead of incremental improvement (wireless, bluetooth, ergonomics etc)</h3>
    </div>

    <div id="Mobility" class="step" data-x="-4500" data-y="-1000">
    <h1>Driver #1 - Mobility</h1>
    <h3>Users are on the go - and the UI must follow</h3>
    </div>

    <div id="Chained" class="step slide" data-x="-3001" data-y="-1000">
    <h2>Chained to the desk?</h2>
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/qfcreF">Chained</em> via clement127 on Flickr.</a></p>
    </div>

    <div id="InfraRedKeyboard" class="step slide" data-x="-1501" data-y="-1000">
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/dRroDq">infrared keyboard on a table for your iPhone</em> via Francisco Huguenin Uhlfelder on Flickr.</a></p>
    </div>

    <div id="ContextsBlurring" class="step" data-x="1" data-y="-1000">
    <h1>Driver #2 - Contexts and context-switching</h1>
    <h3>Users operate in different contexts - and the UI must be appropriate for the context</h3>
    </div>

    <div id="Contexts" class="step slide" data-x="1501" data-y="-1000">
    <h2>Timeslicing throughout the day</h2>
    </div>

    <div id="Haber" class="step" data-x="3002" data-y="-1000">
    <h2>Haber's classification of contexts</h2>
    <h3>Intimate space</h3>
    <h3>Personal space</h3>
    <h3>Social space</h3>
    <h3>Public space</h3>
    </div>

    <div id="InterfacesEverywhere" class="step" data-x="4501" data-y="-1000">
    <h1>Driver #3 - Interfaces are everywhere</h1>
    <h3>Interfaces exist in a landscape <em>with</em> other interfaces, <em>not in isolation</em></h3>
    </div>

    <div id="Ubiquitous" class="step slide" data-x="6001" data-y="-1000">
    </div>

    <div id="Tesla" class="step slide" data-x="7501" data-y="-1000">
    </div>

    <!--- SPEECH RECOGNITION AND VOICE CONTROL -->

    <div id="SpeechRecognition" class="step" data-x="-6000" data-y="0">
    <h1>Speech recognition, voice control and conversational UIs</h1>
    </div>

    <div id="CogniToys" class="step slide" data-x="-4500" data-y="0">
    </div>

    <div id="MirroredDevices" class="step slide" data-x="-3001" data-y="0">
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/6mnbeC">Mirrored Drives</em> via Ian Sterling on Flickr.</a></p>
    </div>

    <!--- GESTURE CONTROL AND NATURAL USER INTERFACES -->

    <div id="GestureControl" class="step" data-x="-6000" data-y="1000">
    <h1>Gesture control and natural user interfaces</h1>
    </div>

    <div id="LEAPMotion" class="step slide" data-x="-4500" data-y="1000">
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/fn6cqk">Leap Motion Hand Tracking</em> via 0xF2 on Flickr.</a></p>
    </div>

    <div id="ProjectSoli" class="step slide" data-x="-3001" data-y="1000">
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/DG9KbX">Project Soli</em> via Portal GDA on Flickr.</a></p>
    </div>

    <div id="NinjaSphere" class="step slide" data-x="-1501" data-y="1000">
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/DG9KbX">Project Soli</em> via Portal GDA on Flickr.</a></p>
    </div>

    <div id="ElderlyWoman" class="step slide" data-x="1" data-y="1000">
    <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/DG9KbX">Keeping up with the times</em> via Mister G.C. on Flickr.</a></p>
    </div>

    <!--- EMOTIONAL AND SOCIAL INTERFACES -->

    <div id="EmotionalSocial" class="step" data-x="-6000" data-y="2000">
    <h1>Emotional and social interfaces</h1>
    </div>

    <div id="Emotiv" class="step slide" data-x="-4500" data-y="2000">
    </div>

    <div id="Affectiva" class="step slide" data-x="-3001" data-y="2000">
    </div>

    <div id="CVDazzle" class="step slide" data-x="-1501" data-y="2000">
      <p class="attribution"><strong>Attribution</strong>: CV Dazzle Collection via Adam Harvey</a></p>
    </div>


    <!--- WEARABLE INTERFACES -->

    <div id="Wearable" class="step" data-x="-6000" data-y="3000">
    <h1>Wearable interfaces</h1>
    </div>

    <div id="Lilypad" class="step slide" data-x="-4500" data-y="3000">
    </div>

    <div id="ProjectJacquard" class="step slide" data-x="-3001" data-y="3000">
    </div>

    <!--- NEXT STEPS AND CONSIDERATIONS -->

    <div id="Considerations" class="step" data-x="-6000" data-y="4000">
    <h1>The law of unintended consequences...</h1>
    </div>

    <div id="KeyboardChaos" class="step slide" data-x="-4500" data-y="4000">
          <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/idr62E">Information Overload</em> via James Marvin Phelps on Flickr.</a></p>
    </div>

    <div id="Usability" class="step slide" data-x="-3001" data-y="4000">
          <p class="attribution"><strong>Attribution</strong>: <a href="https://flic.kr/p/idr62E">Blind Man Walking</em> via Meena Kadri on Flickr.</a></p>
    </div>

<!-- CONCLUSION -->

<div id="Conclusion" class="step" data-x="-6000" data-y="5000">
<h1>Conclusion</h1>
<h3>Mobility, context switching, interfaces everywhere<h3>
<h3>Speech recognition, natural user interfaces and gesture control, emotional UIs and wearables</h3>
</div>

<div id="ConclusionThought" class="step" data-x="-4500" data-y="5000">
<h1><em>How</em> we harness these technologies will shape the future. Use your control <em>wisely</em>. </h1>
</div>

<!-- REFERENCES -->

<div id="References" class="step" data-x="-3001" data-y="5000">
<h1>References</h1>

  <div class="csl-entry">Boehm, J. (2012). Natural user interface sensors for human body measurement. <i>International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences</i>, <i>39</i>, 531–536.</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Natural%20user%20interface%20sensors%20for%20human%20body%20measurement&amp;rft.jtitle=International%20Archives%20of%20the%20Photogrammetry%2C%20Remote%20Sensing%20and%20Spatial%20Information%20Sciences&amp;rft.volume=39&amp;rft.aufirst=J.&amp;rft.aulast=Boehm&amp;rft.au=J.%20Boehm&amp;rft.date=2012&amp;rft.pages=531-536&amp;rft.spage=531&amp;rft.epage=536"></span>
  <div class="csl-entry">Braga, M. (n.d.). Here’s What’s Holding Back Your Universal Translator | Motherboard. Retrieved August 7, 2016, from http://motherboard.vice.com/read/heres-whats-holding-back-your-universal-translator</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft.type=webpage&amp;rft.title=Here's%20What's%20Holding%20Back%20Your%20Universal%20Translator%20%7C%20Motherboard&amp;rft.identifier=http%3A%2F%2Fmotherboard.vice.com%2Fread%2Fheres-whats-holding-back-your-universal-translator&amp;rft.aufirst=Matthew&amp;rft.aulast=Braga&amp;rft.au=Matthew%20Braga"></span>
  <div class="csl-entry">Brownlee, J. (n.d.). Conversational Interfaces, Explained | Co.Design | business + design. Retrieved August 7, 2016, from http://www.fastcodesign.com/3058546/conversational-interfaces-explained</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft.type=webpage&amp;rft.title=Conversational%20Interfaces%2C%20Explained%20%7C%20Co.Design%20%7C%20business%20%2B%20design&amp;rft.identifier=http%3A%2F%2Fwww.fastcodesign.com%2F3058546%2Fconversational-interfaces-explained&amp;rft.aufirst=John&amp;rft.aulast=Brownlee&amp;rft.au=John%20Brownlee"></span>
  <div class="csl-entry">Brumitt, B., &amp; Cadiz, J. J. (2001). Let there be light" examining interfaces for homes of the future. In <i>Human Computer Interaction. INTERACT’01. IFIP TC. 13 International Conference on Human Computer Interaction. IOS Press, Amsterdam, Netherlands; 2001; xxvii+ 897 pp</i> (pp. 375–82).</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Let%20there%20be%20light%22%20examining%20interfaces%20for%20homes%20of%20the%20future&amp;rft.btitle=Human%20Computer%20Interaction.%20INTERACT'01.%20IFIP%20TC.%2013%20International%20Conference%20on%20Human%20Computer%20Interaction.%20IOS%20Press%2C%20Amsterdam%2C%20Netherlands%3B%202001%3B%20xxvii%2B%20897%20pp&amp;rft.aufirst=Barry&amp;rft.aulast=Brumitt&amp;rft.au=Barry%20Brumitt&amp;rft.au=Jonathan%20J.%20Cadiz&amp;rft.date=2001&amp;rft.pages=375-82&amp;rft.spage=375&amp;rft.epage=82"></span>
  <div class="csl-entry">David W. Cearley. (n.d.). The Evolving User Interface From Graphical UI to Environmental UI - Gartner Research ID G00138271. Retrieved August 3, 2016, from https://www.gartner.com/doc/490171/evolving-user-interface-graphical-ui</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft.type=webpage&amp;rft.title=The%20Evolving%20User%20Interface%20From%20Graphical%20UI%20to%20Environmental%20UI%20-%20Gartner%20Research%20ID%20G00138271&amp;rft.identifier=https%3A%2F%2Fwww.gartner.com%2Fdoc%2F490171%2Fevolving-user-interface-graphical-ui&amp;rft.aulast=David%20W.%20Cearley&amp;rft.au=David%20W.%20Cearley"></span>
  <div class="csl-entry">Delimarschi, D., Swartzendruber, G., &amp; Kagdi, H. (2014). Enabling integrated development environments with natural user interface interactions. In <i>Proceedings of the 22nd International Conference on Program Comprehension</i> (pp. 126–129). ACM.</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=urn%3Aisbn%3A1-4503-2879-2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Enabling%20integrated%20development%20environments%20with%20natural%20user%20interface%20interactions&amp;rft.btitle=Proceedings%20of%20the%2022nd%20International%20Conference%20on%20Program%20Comprehension&amp;rft.publisher=ACM&amp;rft.aufirst=Denis&amp;rft.aulast=Delimarschi&amp;rft.au=Denis%20Delimarschi&amp;rft.au=George%20Swartzendruber&amp;rft.au=Huzefa%20Kagdi&amp;rft.date=2014&amp;rft.pages=126-129&amp;rft.spage=126&amp;rft.epage=129&amp;rft.isbn=1-4503-2879-2"></span>
  <div class="csl-entry">Haber, J., Greening, M., Castellano, L., &amp; Wheaton, P. (n.d.). Proxemic Conversational UI: Moving beyond simple conversation.</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Proxemic%20Conversational%20UI%3A%20Moving%20beyond%20simple%20conversation&amp;rft.aufirst=Jonathan&amp;rft.aulast=Haber&amp;rft.au=Jonathan%20Haber&amp;rft.au=Mike%20Greening&amp;rft.au=Lauren%20Castellano&amp;rft.au=Phillip%20Wheaton"></span>
  <div class="csl-entry">Harris, R. A. (2004). <i>Voice interaction design: crafting the new conversational speech systems</i>. Elsevier.</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=urn%3Aisbn%3A0-08-047480-2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Voice%20interaction%20design%3A%20crafting%20the%20new%20conversational%20speech%20systems&amp;rft.publisher=Elsevier&amp;rft.aufirst=Randy%20Allen&amp;rft.aulast=Harris&amp;rft.au=Randy%20Allen%20Harris&amp;rft.date=2004&amp;rft.isbn=0-08-047480-2"></span>
  <div class="csl-entry">Jackie Fenn, Alexander Linden, Steve Cramoysan, Toby Bell, &amp; Bern Elliot. (n.d.). Hype Cycle for Human-Computer Interaction, 2005 Gartner Research ID G00128069. Retrieved August 3, 2016, from https://www.gartner.com/doc/481880?ref=ddisp</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft.type=webpage&amp;rft.title=Hype%20Cycle%20for%20Human-Computer%20Interaction%2C%202005%20Gartner%20Research%20ID%20G00128069&amp;rft.identifier=https%3A%2F%2Fwww.gartner.com%2Fdoc%2F481880%3Fref%3Dddisp&amp;rft.aulast=Jackie%20Fenn&amp;rft.au=Jackie%20Fenn&amp;rft.au=Alexander%20Linden&amp;rft.au=Steve%20Cramoysan&amp;rft.au=Toby%20Bell&amp;rft.au=Bern%20Elliot"></span>
  <div class="csl-entry">Jain, J., Lund, A., &amp; Wixon, D. (2011). The future of natural user interfaces. In <i>CHI ’11 Extended Abstracts on Human Factors in Computing Systems</i> (pp. 211–214). Vancouver, BC, Canada: ACM.</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=urn%3Aisbn%3A978-1-4503-0268-5&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=The%20future%20of%20natural%20user%20interfaces&amp;rft.btitle=CHI%20'11%20Extended%20Abstracts%20on%20Human%20Factors%20in%20Computing%20Systems&amp;rft.place=Vancouver%2C%20BC%2C%20Canada&amp;rft.publisher=ACM&amp;rft.aufirst=Jhilmil&amp;rft.aulast=Jain&amp;rft.au=Jhilmil%20Jain&amp;rft.au=Arnold%20Lund&amp;rft.au=Dennis%20Wixon&amp;rft.date=2011&amp;rft.pages=211-214&amp;rft.spage=211&amp;rft.epage=214&amp;rft.isbn=978-1-4503-0268-5"></span>
  <div class="csl-entry">Koskela, T., &amp; Väänänen-Vainio-Mattila, K. (2004). Evolution towards smart home environments: empirical evaluation of three user interfaces. <i>Personal and Ubiquitous Computing</i>, <i>8</i>(3–4), 234–240.</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Evolution%20towards%20smart%20home%20environments%3A%20empirical%20evaluation%20of%20three%20user%20interfaces&amp;rft.jtitle=Personal%20and%20Ubiquitous%20Computing&amp;rft.volume=8&amp;rft.issue=3-4&amp;rft.aufirst=Tiiu&amp;rft.aulast=Koskela&amp;rft.au=Tiiu%20Koskela&amp;rft.au=Kaisa%20V%C3%A4%C3%A4n%C3%A4nen-Vainio-Mattila&amp;rft.date=2004&amp;rft.pages=234-240&amp;rft.spage=234&amp;rft.epage=240"></span>
  <div class="csl-entry">Lee, E. J., Nass, C., &amp; Brave, S. (2000). Can computer-generated speech have gender?: an experimental test of gender stereotype. In <i>CHI’00 extended abstracts on Human factors in computing systems</i> (pp. 289–290). ACM.</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=urn%3Aisbn%3A1-58113-248-4&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Can%20computer-generated%20speech%20have%20gender%3F%3A%20an%20experimental%20test%20of%20gender%20stereotype&amp;rft.btitle=CHI'00%20extended%20abstracts%20on%20Human%20factors%20in%20computing%20systems&amp;rft.publisher=ACM&amp;rft.aufirst=Eun%20Ju&amp;rft.aulast=Lee&amp;rft.au=Eun%20Ju%20Lee&amp;rft.au=Clifford%20Nass&amp;rft.au=Scott%20Brave&amp;rft.date=2000&amp;rft.pages=289-290&amp;rft.spage=289&amp;rft.epage=290&amp;rft.isbn=1-58113-248-4"></span>
  <div class="csl-entry">Nass, C., Moon, Y., &amp; Green, N. (1997). Are Machines Gender Neutral? Gender‐Stereotypic Responses to Computers With Voices. <i>Journal of Applied Social Psychology</i>, <i>27</i>(10), 864–876.</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Are%20Machines%20Gender%20Neutral%3F%20Gender%E2%80%90Stereotypic%20Responses%20to%20Computers%20With%20Voices&amp;rft.jtitle=Journal%20of%20applied%20social%20psychology&amp;rft.volume=27&amp;rft.issue=10&amp;rft.aufirst=Clifford&amp;rft.aulast=Nass&amp;rft.au=Clifford%20Nass&amp;rft.au=Youngme%20Moon&amp;rft.au=Nancy%20Green&amp;rft.date=1997&amp;rft.pages=864-876&amp;rft.spage=864&amp;rft.epage=876"></span>
  <div class="csl-entry">Picard, R. W., Wexelblat, A., &amp; Clifford I Nass, C. I. N. I. (2002). Future interfaces: social and emotional. In <i>CHI’02 Extended Abstracts on Human Factors in Computing Systems</i> (pp. 698–699). ACM.</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=urn%3Aisbn%3A1-58113-454-1&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Future%20interfaces%3A%20social%20and%20emotional&amp;rft.btitle=CHI'02%20Extended%20Abstracts%20on%20Human%20Factors%20in%20Computing%20Systems&amp;rft.publisher=ACM&amp;rft.aufirst=Rosalind%20W.&amp;rft.aulast=Picard&amp;rft.au=Rosalind%20W.%20Picard&amp;rft.au=Alan%20Wexelblat&amp;rft.au=Clifford%20I.%20Nass%20I.%20Clifford%20I%20Nass&amp;rft.date=2002&amp;rft.pages=698-699&amp;rft.spage=698&amp;rft.epage=699&amp;rft.isbn=1-58113-454-1"></span>
  <div class="csl-entry">Steinberg, G. (2012). Natural user interfaces. In <i>ACM SIGCHI Conference on Human Factors in Computing Systems</i>.</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Natural%20user%20interfaces&amp;rft.btitle=ACM%20SIGCHI%20Conference%20on%20Human%20Factors%20in%20Computing%20Systems&amp;rft.aufirst=Gideon&amp;rft.aulast=Steinberg&amp;rft.au=Gideon%20Steinberg&amp;rft.date=2012"></span>
  <div class="csl-entry">Štolfa, T. (n.d.). The Future of Conversational UI Belongs to Hybrid Interfaces — The Layer — Medium. Retrieved August 7, 2016, from https://medium.com/the-layer/the-future-of-conversational-ui-belongs-to-hybrid-interfaces-8a228de0bdb5#.613h0diz3</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft.type=webpage&amp;rft.title=The%20Future%20of%20Conversational%20UI%20Belongs%20to%20Hybrid%20Interfaces%20%E2%80%94%20The%20Layer%20%E2%80%94%20Medium&amp;rft.identifier=https%3A%2F%2Fmedium.com%2Fthe-layer%2Fthe-future-of-conversational-ui-belongs-to-hybrid-interfaces-8a228de0bdb5%23.613h0diz3&amp;rft.aufirst=Toma%C5%BE&amp;rft.aulast=%C5%A0tolfa&amp;rft.au=Toma%C5%BE%20%C5%A0tolfa"></span>
  <div class="csl-entry">The evolution of the interface, from text through touch | Ars Technica. (n.d.). Retrieved August 4, 2016, from http://arstechnica.com/gadgets/2015/04/the-evolution-of-the-interface-from-text-through-touch/</div>
  <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft.type=webpage&amp;rft.title=The%20evolution%20of%20the%20interface%2C%20from%20text%20through%20touch%20%7C%20Ars%20Technica&amp;rft.identifier=http%3A%2F%2Farstechnica.com%2Fgadgets%2F2015%2F04%2Fthe-evolution-of-the-interface-from-text-through-touch%2F"></span>
</div>

<!-- FLUFF -->

<div id="overview" class="step" data-x="3002" data-y="0" data-scale="10">
</div>

</div>

<div class="hint">
    <p>Use a spacebar or arrow keys to navigate</p>
</div>
<script>
if ("ontouchstart" in document.documentElement) {
    document.querySelector(".hint").innerHTML = "<p>Tap on the left or right to navigate</p>";
}
</script>
<script src="js/impress.js"></script>
<script>impress().init();</script>

</body>
</html>
